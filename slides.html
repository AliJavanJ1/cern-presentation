<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-befe23ebd2f54d8af2c8a89d1a1611f1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.34">

  <meta name="author" content="Ali Javani">
  <meta name="dcterms.date" content="2025-03-09">
  <title>PicoCal Autoencoder</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-175ec1c0ea92bc532c45781632c4e35e.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-visibility="hidden" class="quarto-title-block center">
  <h1 class="title">PicoCal Autoencoder</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Ali Javani 
</div>
</div>
</div>

  <p class="date">2025-03-09</p>
</section>
<section>
<section id="section" class="title-slide slide level1 center">
<h1></h1>
<div style="text-align:center; margin-bottom:1.2rem;">
<h1 style="font-size: 2.3em;">
PicoCal Autoencoder Optimization
</h1>
<p>
<strong>Presenter:</strong> Ali Javani
</p>
<p>
<strong>Supervisers:</strong> Dr.&nbsp;Vladimir Loncar • Prof.&nbsp;Eluned Smith
</p>
<p style="font-size: .6em;">
<strong>Co-Supervisors:</strong> Dr.&nbsp;Julian Garcia Pardinas • Dr.&nbsp;Katya Govorkova
</p>
</div>
<div style="display:flex; justify-content:center; gap:20px">
<div>
<img src="assets/images/psl.svg" alt="Main University" style="height:70px; filter: brightness(1.5)">
</div>
<div>
<img src="assets/images/cern.png" alt="Another Affiliation" style="height:70px; brightness(1.5)">
</div>
<div>
<img src="assets/images/sft.png" alt="Institute of Advanced Things" style="height:70px; brightness(1.5)">
</div>
<div>
<img src="assets/images/mit.png" alt="Another Affiliation" style="height:70px; brightness(1.5)">
</div>
</div>
</section>
<section id="interactive-plotly" class="slide level2">
<h2>Interactive Plotly</h2>
<div id="8c172e6c" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
        <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
        </script>
        <script type="module">import "https://cdn.plot.ly/plotly-3.1.0.min"</script>
        
</div>
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.1.0.min.js" integrity="sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=" crossorigin="anonymous"></script>                <div id="0c589b5e-066b-449a-a140-2c68bd373a1e" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("0c589b5e-066b-449a-a140-2c68bd373a1e")) {                    Plotly.newPlot(                        "0c589b5e-066b-449a-a140-2c68bd373a1e",                        [{"hovertemplate":"species=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"setosa","orientation":"v","showlegend":true,"x":{"dtype":"f8","bdata":"AAAAAAAADEAAAAAAAAAIQJqZmZmZmQlAzczMzMzMCEDNzMzMzMwMQDMzMzMzMw9AMzMzMzMzC0AzMzMzMzMLQDMzMzMzMwdAzczMzMzMCECamZmZmZkNQDMzMzMzMwtAAAAAAAAACEAAAAAAAAAIQAAAAAAAABBAmpmZmZmZEUAzMzMzMzMPQAAAAAAAAAxAZmZmZmZmDkBmZmZmZmYOQDMzMzMzMwtAmpmZmZmZDUDNzMzMzMwMQGZmZmZmZgpAMzMzMzMzC0AAAAAAAAAIQDMzMzMzMwtAAAAAAAAADEAzMzMzMzMLQJqZmZmZmQlAzczMzMzMCEAzMzMzMzMLQGZmZmZmZhBAzczMzMzMEEDNzMzMzMwIQJqZmZmZmQlAAAAAAAAADEDNzMzMzMwIQAAAAAAAAAhAMzMzMzMzC0AAAAAAAAAMQGZmZmZmZgJAmpmZmZmZCUAAAAAAAAAMQGZmZmZmZg5AAAAAAAAACEBmZmZmZmYOQJqZmZmZmQlAmpmZmZmZDUBmZmZmZmYKQA=="},"xaxis":"x","y":{"dtype":"f8","bdata":"ZmZmZmZmFECamZmZmZkTQM3MzMzMzBJAZmZmZmZmEkAAAAAAAAAUQJqZmZmZmRVAZmZmZmZmEkAAAAAAAAAUQJqZmZmZmRFAmpmZmZmZE0CamZmZmZkVQDMzMzMzMxNAMzMzMzMzE0AzMzMzMzMRQDMzMzMzMxdAzczMzMzMFkCamZmZmZkVQGZmZmZmZhRAzczMzMzMFkBmZmZmZmYUQJqZmZmZmRVAZmZmZmZmFEBmZmZmZmYSQGZmZmZmZhRAMzMzMzMzE0AAAAAAAAAUQAAAAAAAABRAzczMzMzMFEDNzMzMzMwUQM3MzMzMzBJAMzMzMzMzE0CamZmZmZkVQM3MzMzMzBRAAAAAAAAAFkCamZmZmZkTQAAAAAAAABRAAAAAAAAAFkCamZmZmZkTQJqZmZmZmRFAZmZmZmZmFEAAAAAAAAAUQAAAAAAAABJAmpmZmZmZEUAAAAAAAAAUQGZmZmZmZhRAMzMzMzMzE0BmZmZmZmYUQGZmZmZmZhJAMzMzMzMzFUAAAAAAAAAUQA=="},"yaxis":"y","type":"scatter"},{"hovertemplate":"species=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"versicolor","orientation":"v","showlegend":true,"x":{"dtype":"f8","bdata":"mpmZmZmZCUCamZmZmZkJQM3MzMzMzAhAZmZmZmZmAkBmZmZmZmYGQGZmZmZmZgZAZmZmZmZmCkAzMzMzMzMDQDMzMzMzMwdAmpmZmZmZBUAAAAAAAAAAQAAAAAAAAAhAmpmZmZmZAUAzMzMzMzMHQDMzMzMzMwdAzczMzMzMCEAAAAAAAAAIQJqZmZmZmQVAmpmZmZmZAUAAAAAAAAAEQJqZmZmZmQlAZmZmZmZmBkAAAAAAAAAEQGZmZmZmZgZAMzMzMzMzB0AAAAAAAAAIQGZmZmZmZgZAAAAAAAAACEAzMzMzMzMHQM3MzMzMzARAMzMzMzMzA0AzMzMzMzMDQJqZmZmZmQVAmpmZmZmZBUAAAAAAAAAIQDMzMzMzMwtAzczMzMzMCEBmZmZmZmYCQAAAAAAAAAhAAAAAAAAABEDNzMzMzMwEQAAAAAAAAAhAzczMzMzMBEBmZmZmZmYCQJqZmZmZmQVAAAAAAAAACEAzMzMzMzMHQDMzMzMzMwdAAAAAAAAABEBmZmZmZmYGQA=="},"xaxis":"x","y":{"dtype":"f8","bdata":"AAAAAAAAHECamZmZmZkZQJqZmZmZmRtAAAAAAAAAFkAAAAAAAAAaQM3MzMzMzBZAMzMzMzMzGUCamZmZmZkTQGZmZmZmZhpAzczMzMzMFEAAAAAAAAAUQJqZmZmZmRdAAAAAAAAAGEBmZmZmZmYYQGZmZmZmZhZAzczMzMzMGkBmZmZmZmYWQDMzMzMzMxdAzczMzMzMGEBmZmZmZmYWQJqZmZmZmRdAZmZmZmZmGEAzMzMzMzMZQGZmZmZmZhhAmpmZmZmZGUBmZmZmZmYaQDMzMzMzMxtAzczMzMzMGkAAAAAAAAAYQM3MzMzMzBZAAAAAAAAAFkAAAAAAAAAWQDMzMzMzMxdAAAAAAAAAGECamZmZmZkVQAAAAAAAABhAzczMzMzMGkAzMzMzMzMZQGZmZmZmZhZAAAAAAAAAFkAAAAAAAAAWQGZmZmZmZhhAMzMzMzMzF0AAAAAAAAAUQGZmZmZmZhZAzczMzMzMFkDNzMzMzMwWQM3MzMzMzBhAZmZmZmZmFEDNzMzMzMwWQA=="},"yaxis":"y","type":"scatter"},{"hovertemplate":"species=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica","marker":{"color":"#00cc96","symbol":"circle"},"mode":"markers","name":"virginica","orientation":"v","showlegend":true,"x":{"dtype":"f8","bdata":"ZmZmZmZmCkCamZmZmZkFQAAAAAAAAAhAMzMzMzMzB0AAAAAAAAAIQAAAAAAAAAhAAAAAAAAABEAzMzMzMzMHQAAAAAAAAARAzczMzMzMDECamZmZmZkJQJqZmZmZmQVAAAAAAAAACEAAAAAAAAAEQGZmZmZmZgZAmpmZmZmZCUAAAAAAAAAIQGZmZmZmZg5AzczMzMzMBECamZmZmZkBQJqZmZmZmQlAZmZmZmZmBkBmZmZmZmYGQJqZmZmZmQVAZmZmZmZmCkCamZmZmZkJQGZmZmZmZgZAAAAAAAAACEBmZmZmZmYGQAAAAAAAAAhAZmZmZmZmBkBmZmZmZmYOQGZmZmZmZgZAZmZmZmZmBkDNzMzMzMwEQAAAAAAAAAhAMzMzMzMzC0DNzMzMzMwIQAAAAAAAAAhAzczMzMzMCEDNzMzMzMwIQM3MzMzMzAhAmpmZmZmZBUCamZmZmZkJQGZmZmZmZgpAAAAAAAAACEAAAAAAAAAEQAAAAAAAAAhAMzMzMzMzC0AAAAAAAAAIQA=="},"xaxis":"x","y":{"dtype":"f8","bdata":"MzMzMzMzGUAzMzMzMzMXQGZmZmZmZhxAMzMzMzMzGUAAAAAAAAAaQGZmZmZmZh5AmpmZmZmZE0AzMzMzMzMdQM3MzMzMzBpAzczMzMzMHEAAAAAAAAAaQJqZmZmZmRlAMzMzMzMzG0DNzMzMzMwWQDMzMzMzMxdAmpmZmZmZGUAAAAAAAAAaQM3MzMzMzB5AzczMzMzMHkAAAAAAAAAYQJqZmZmZmRtAZmZmZmZmFkDNzMzMzMweQDMzMzMzMxlAzczMzMzMGkDNzMzMzMwcQM3MzMzMzBhAZmZmZmZmGECamZmZmZkZQM3MzMzMzBxAmpmZmZmZHUCamZmZmZkfQJqZmZmZmRlAMzMzMzMzGUBmZmZmZmYYQM3MzMzMzB5AMzMzMzMzGUCamZmZmZkZQAAAAAAAABhAmpmZmZmZG0DNzMzMzMwaQJqZmZmZmRtAMzMzMzMzF0AzMzMzMzMbQM3MzMzMzBpAzczMzMzMGkAzMzMzMzMZQAAAAAAAABpAzczMzMzMGECamZmZmZkXQA=="},"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"sepal_width"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"sepal_length"}},"legend":{"title":{"text":"species"},"tracegroupgap":0},"title":{"text":"Iris (interactive)"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('0c589b5e-066b-449a-a140-2c68bd373a1e');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
</section></section>
<section>
<section id="project-overview" class="title-slide slide level1 center">
<h1>Project overview</h1>
<p>The model compresses and reconstructs the pulses measured in the <strong>PicoCal</strong> calorimeter. Each pulse is normally stored as <strong>32 samples</strong> (already downsampled from a longer waveform). Transmitting and saving all of this is challenging because the detector will record <strong>millions of pulses per second</strong>.</p>
</section>
<section class="slide level2">

<p>Our <strong>autoencoder</strong> takes each 32-point pulse and compresses it to a <strong>2-dimensional latent</strong>. These two numbers capture key features (size, shape, timing). The <strong>encoder</strong> runs <strong>on-detector</strong> so only the compressed representation is transmitted; the <strong>decoder</strong> reconstructs the full 32-sample pulse downstream.</p>
</section>
<section class="slide level2">

<p>Compared with simpler methods that keep only a timestamp, this preserves much more information about the <strong>pulse shape</strong>, improving:</p>
<ul>
<li><strong>Time reconstruction:</strong> precise hit timing.</li>
<li><strong>Energy calibration:</strong> mapping the wave amplitude to deposited energy.</li>
<li><strong>Pile-up mitigation:</strong> separating overlapping signals.</li>
</ul>
</section></section>
<section>
<section id="what-is-an-autoencoder" class="title-slide slide level1 center">
<h1>What is an Autoencoder?</h1>
<p>An autoencoder learns a compact representation (<strong>encoder</strong>) and a reconstruction (<strong>decoder</strong>).</p>
<p>Our baseline: <strong>32 → 2 → 32</strong> (encoder → bottleneck → decoder). The encoder is the on-detector component; the decoder is offline.</p>
<p>So, the bottleneck would retain most of the information</p>
</section>
<section class="slide level2">


<img data-src="assets/images/autoencoder.png" class="r-stretch"></section></section>
<section>
<section id="data-used-for-training" class="title-slide slide level1 center">
<h1>Data used for training</h1>
<p>Training and testing data come from a detailed simulation of the PicoCal electromagnetic calorimeter, including the detector geometry, materials, and readout electronics, so simulated pulses resemble those expected during LHCb data-taking.</p>
</section>
<section class="slide level2">

<p>We generate two pulse types and then mix them to mimic realistic running conditions:</p>
<ul>
<li><strong>Signal pulses:</strong> single photons, 0.5–5 GeV, produced near the interaction point.</li>
<li><strong>Background pulses:</strong> extra detector activity (for example: pile-up, underlying event).</li>
</ul>
<p>Each pulse is first simulated with <strong>1024 samples</strong> (as in the actual test-beam digitizer). The detector will use a different digitizer with <strong>32 samples</strong>, so we <strong>downsample</strong> 1024→32 to match. This preserves overall shape but not exact timing.</p>
</section></section>
<section>
<section id="current-status-work-done-so-far" class="title-slide slide level1 center">
<h1>Current status (work done so far)</h1>
<ul>
<li>A baseline autoencoder is <strong>trained</strong>.</li>
<li>An <strong>hls4ml</strong> implementation exists for <strong>hardware deployment</strong> of the encoder.</li>
</ul>
</section>
<section id="what-i-am-going-to-do" class="slide level2">
<h2>What I am going to do</h2>
<p>Optimize the model via <strong>quantization</strong>, focusing on the <strong>encoder</strong>.</p>
</section></section>
<section id="why-we-need-quantize" class="title-slide slide level1 center">
<h1>Why we need quantize? <!--(confirm priorities with Katya???)--></h1>
<ul>
<li><strong>Smaller &amp; cheaper:</strong> fewer bits → less memory and bandwidth per pulse.</li>
<li><strong>Faster &amp; lower latency:</strong> integer arithmetic is hardware-friendly.</li>
<li><strong>Lower power:</strong> critical for on-detector operation.</li>
<li><strong>Robustness:</strong> with <strong>QAT</strong>, accuracy can match (or sometimes slightly improve vs.&nbsp;FP) due to regularization.</li>
<li><strong>Smaller output payload:</strong> compressed latent uses fewer bits per value.</li>
</ul>
</section>

<section id="quantization-options-summary" class="title-slide slide level1 center">
<h1>Quantization options (summary)</h1>
<div class="slide" style="font-size:50%">
<table class="caption-top">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Strategy</th>
<th>What it does</th>
<th>Accuracy hit</th>
<th>Speed/Memory win</th>
<th>Typical use cases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>PTQ (static)</strong></td>
<td>Calibrate on a small dataset; bake fixed scales/zero-points.</td>
<td>Low→moderate (good at 8-bit; riskier ≤4-bit)</td>
<td>3–4× smaller; fast INT kernels</td>
<td>Quick CPU/GPU/TPU deploy when retraining is hard.</td>
</tr>
<tr class="even">
<td><strong>PTQ (dynamic)</strong></td>
<td>Weights quantized; activation scales computed at inference.</td>
<td>Similar to static at 8-bit; worse ≤4-bit</td>
<td>Memory win; smaller speedup</td>
<td>NLP on CPUs; no calibration set available.</td>
</tr>
<tr class="odd">
<td><strong>QAT</strong></td>
<td>Train with fake-quant (STE) so model learns quant noise.</td>
<td>Best (works down to 4/2-bit; even ternary)</td>
<td>Runtime like PTQ; higher train cost</td>
<td>Edge/FPGA/ASIC; tight accuracy budgets.</td>
</tr>
<tr class="even">
<td><strong>WOQ</strong></td>
<td>Weight-only (e.g., 4-bit); activations FP8/16.</td>
<td>Small→moderate</td>
<td>Big memory/BW savings</td>
<td>Large LLM/CV on GPUs where memory is the bottleneck.</td>
</tr>
<tr class="odd">
<td><strong>Mixed-precision</strong></td>
<td>Per-layer/per-tensor bit-widths.</td>
<td>Near-float if tuned</td>
<td>Best Pareto trade-off</td>
<td>FPGAs/ASICs (QKeras+hls4ml), mobile SoCs.</td>
</tr>
</tbody>
</table>
</div>
<div class="slide" style="font-size:70%">
<p>Our plan: <strong>Mixed-precision QAT</strong> for the encoder. (using <strong>QKeras + hls4ml</strong>)</p>
</div>
</section>

<section id="qkeras-hls4ml" class="title-slide slide level1 center">
<h1>QKeras + hls4ml</h1>
<p><strong>QKeras is</strong> a drop-in extension of Keras that lets you assign <strong>per-layer</strong> (heterogeneous) quantization to weights, activations, and batch-norm parameters and train the model <strong>quantization-aware</strong>. Combined with <strong>hls4ml</strong>, quantized networks are compiled to FPGA firmware for <strong>O(10) ns</strong> inference.</p>
</section>

<section id="why-im-not-using-autoqkeras" class="title-slide slide level1 center">
<h1>Why I’m not using AutoQKeras</h1>
<p><strong>AutoQKeras</strong> (auto search over bit-widths based on estimated energy or model bit size + accuracy) was <strong>not used</strong> due to:</p>
<ul>
<li>Sparse docs/API; heavy implicit behavior.</li>
<li>Minimal result summaries and limited reliability for our workflow.</li>
<li>No built-in <strong>K-Fold</strong> support;</li>
<li>limited parallelism beyond default Keras options (except Trial parallelism, Data parallelism only suitable for multiple GPUs)</li>
</ul>
</section>

<section>
<section id="environment-constraints-what-currently-works" class="title-slide slide level1 center">
<h1>Environment constraints (what currently works)</h1>
<div class="slide" style="font-size:70%">
<ul>
<li>QKeras works reliably with <strong><code>Python 3.10</code> + <code>TensorFlow 2.14</code> + <code>Keras 2.x</code></strong> in our tests.</li>
<li><strong>Keras v3</strong> APIs are not compatible (errors encountered). There are signs of in-progress support, but it is not usable in our setup yet and updates are so rare.</li>
<li>CUDA/driver combinations: in practice, the project failed with some versions (e.g., ~560, ~580) and ran with an intermediate one (~570) but again, in theory it should be compatible with 570 ≤.</li>
<li>Although some guides suggest <strong><code>TF 2.15</code></strong> (<code>Keras 2.15</code>) or <strong><code>TF ≥ 2.16</code> with <code>tf-keras</code> and <code>TF_USE_LEGACY_KERAS=1</code></strong>, this did not work in our experiments. We therefore <strong>stuck to <code>Python 3.10</code> + <code>TF 2.14</code></strong>.</li>
</ul>
</div>
</section>
<section class="slide level2">

<p><em>Note:</em> I plan to create a short <strong>notebook/markdown guide</strong> for a reproducible QKeras setup (including CERN cluster tips), given the current documentation gaps and the fact that it took a lot of time on setting up a working environment for me.</p>
</section></section>
<section>
<section id="quantization-work-so-far-issues-and-fixes" class="title-slide slide level1 center">
<h1>Quantization work so far — issues and fixes</h1>

</section>
<section id="wrong-baseline-comparison-fixed" class="slide level2">
<h2>Wrong baseline comparison (fixed)</h2>
<p>Initially, the quantized model was asked to reconstruct <strong>unquantized</strong> inputs; this implicitly asks it to “undo” input quantization too.</p>
<p>TODO: show the previous code for quantized model and focus on the line with activation before the model</p>
<p><strong>Fix:</strong> <strong>Quantize the inputs</strong> (data) prior to training so both models see consistent quantization.</p>
</section>
<section id="dying-relu-diagnosis-fixed" class="slide level2">
<h2>“dying ReLU” diagnosis (fixed)</h2>
<p><strong>Intermittent failures (~1/3 runs).</strong></p>
<p>Even after fixing the inputs, about <strong>one-third of runs</strong> failed to learn. Inspection of <strong>weights and biases</strong> showed nothing obviously wrong, yet parameter updates were <strong>tiny or stagnant</strong> across batches/epochs. Probing intermediate <strong>layer outputs</strong> revealed the network was producing <strong>near-constant outputs</strong>, and, crucially, the <strong>encoder ReLU</strong> had a <strong>very high (sometimes ~100%) probability</strong> of outputting <strong>zero</strong> on one or both latent units.</p>
</section>
<section class="slide level2">

<p><strong>Root cause: ReLU + tiny bottleneck → dead units.</strong></p>
<p>With an activation that has an <strong>asymmetric output</strong> (ReLU = zero for all negative pre-activations) and a <strong>bottleneck with very few neurons (latent=2)</strong>, the model often explores <strong>zero outputs</strong> early—before the optimizer is “calibrated.” Once a ReLU unit is stuck at zero, its <strong>gradient is zero</strong> and it cannot recover. This is the <strong>dying ReLU</strong> problem: ReLU neurons become permanently inactive, outputting zero for all inputs and <strong>blocking learning</strong>.</p>
</section>
<section class="slide level2">

<ul>
<li>See: <strong>Against Dead ReLU</strong> (internal note): https://www.notion.so/Against-Dead-Relu-262d089371c98046ae45ddd100d6a2ec?pvs=21</li>
</ul>
<p><strong>Mitigations explored (and what actually worked).</strong></p>
<ul>
<li><strong>Initialization:</strong> Use <strong>He (Kaiming) initialization</strong> instead of Xavier for rectifiers. <span class="citation" data-cites="he2015delvingdeeprectifierssurpassing"><a href="#/references" role="doc-biblioref" onclick="">[1]</a></span></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Normalization:</strong> Some papers suggest placing <strong>Batch Normalization immediately before the activation</strong> (notably in larger models) to stabilize pre-activations. <span class="citation" data-cites="DBLP:journals/corr/IoffeS15"><a href="#/references" role="doc-biblioref" onclick="">[2]</a></span></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Activation variants:</strong> Many works propose <strong>ReLU extensions</strong> (e.g., <strong>Leaky ReLU / PReLU / RReLU</strong>) that keep a <strong>non-zero slope</strong> on the negative side, both <strong>mitigating dead units</strong> and sometimes <strong>improving accuracy</strong>.</li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Regularization for quantization robustness:</strong> One paper recommends <strong>L2 regularization</strong> in quantization-friendly designs for large models—shrinking weight ranges to <strong>reduce quantization error</strong>, which in turn lowers the chance of saturating activations and <strong>killing neurons</strong>: <span class="citation" data-cites="Sheng_2018"><a href="#/references" role="doc-biblioref" onclick="">[3]</a></span></li>
</ul>
</section>
<section class="slide level2">

<ul>
<li><strong>Learning rate:</strong> A <strong>large LR</strong> increases the chance of pushing units into the zero region. I <strong>tuned the LR</strong>, added <strong>warmup</strong>, and experimented with <strong>restarts</strong>; these helped but <strong>did not</strong> fully resolve the issue.</li>
</ul>
</section>
<section class="slide level2">

<p><strong>Outcome.</strong></p>
<p>The <strong>only change that consistently fixed the problem</strong> was <strong>replacing ReLU with Leaky ReLU</strong> in the encoder bottleneck. Other mitigations (He init, BN placement, L2, LR schedules) <strong>did not</strong> noticeably alleviate the issue in our <strong>small</strong> model, likely because many of those results are demonstrated on <strong>larger architectures</strong>.</p>
</section>
<section class="slide level2">

<p><strong>Operational safeguard.</strong></p>
<p>I also implemented a <strong>callback</strong> to detect dying behavior (monitoring <strong>zero-output ratio</strong> and <strong>learning stalls</strong>) and to <strong>reinitialize</strong>. However, reinitializing <strong>layers/activations/callbacks/epochs mid-training</strong> made the code overly complex. Instead, I adopted a simpler <strong>restart policy</strong> triggered by <strong>high validation loss</strong>, which works well in practice.</p>
<blockquote>
<p>(Slide note: include a small example where training stops due to near-zero latent outputs.)</p>
</blockquote>
</section></section>
<section id="variance-across-runs-and-k-fold-cross-validation" class="title-slide slide level1 center">
<h1>Variance across runs and K-Fold cross-validation</h1>
<div class="slide" style="font-size:70%">
<p>The <strong>std</strong> of the <strong>minimum validation loss</strong> was high (≈ half the mean). To obtain a more stable estimate:</p>
<ul>
<li>Used <strong>K-Fold CV (K=10)</strong> to report an average with variance.</li>
<li>Sequential training became slow; tried multiprocessing with shared GPU but ran into errors.</li>
<li>Switched to a clearer approach using <strong><code>subprocess.Popen</code></strong> to launch independent training processes, reschedule failures, and keep the parallelism logic outside the training code.</li>
</ul>
<p><em>(Include a small <code>subprocess.Popen</code> snippet on the slide if you want to show the launch pattern.)</em></p>
</div>
</section>

<section id="what-to-optimize-next-and-why" class="title-slide slide level1 center">
<h1>What to optimize next (and why)</h1>
<div class="slide" style="font-size:70%">
<ul>
<li><strong># encoder layers:</strong> adding encoder depth doubles on-detector latency; avoid unless justified.</li>
<li><strong># decoder layers:</strong> can be increased (offline) to improve reconstruction and better expose the bottleneck capacity.</li>
<li><strong>Quantizing encoder weights/biases:</strong> evaluate experimentally (likely symmetric per-channel weights; higher-precision biases).</li>
<li><strong>Quantizing encoder output activation:</strong> evaluate carefully (see §13).</li>
<li><strong>Latent dimensionality:</strong> we tested 2→5 for insight; <strong>spec requires 2</strong>, so we will stick to 2.</li>
</ul>
</div>
</section>

<section>
<section id="parameter-ranges-and-early-experiments" class="title-slide slide level1 scrollable center">
<h1>Parameter ranges and early experiments</h1>
<ul>
<li><strong>Weights/biases:</strong> observed magnitudes are small; <strong>integer bits 0–2</strong> seem sufficient. With <strong>10–15 fractional bits</strong>, quantization error is well below the model’s validation loss per parameter.</li>
</ul>
<blockquote>
<p>add the based model results</p>
</blockquote>
</section>
<section class="slide level2">

<ul>
<li><strong>Activations Outputs:</strong> much <strong>wider dynamic range</strong>; they need more integer bits, making them harder to quantize aggressively.</li>
</ul>
<blockquote>
<p>add outputs</p>
</blockquote>
</section>
<section class="slide level2">

<p>Experiments:</p>
<ul>
<li>Quantizing <strong>only the encoder output activation</strong> gave inconsistent results (sensitive/random).</li>
</ul>
<blockquote>
<p>add outputs</p>
</blockquote>
</section>
<section class="slide level2">

<ul>
<li>Keeping that activation <strong>unquantized</strong>, we scanned <strong>latent sizes 2–5</strong>: moving from <strong>2 → 3</strong> latents improved accuracy by ~4× with ~1.5× model/energy cost, but <strong>spec confines us to 2 latents</strong> (post-review), and gains from <strong>3→4→5</strong> were not compelling.</li>
</ul>
<blockquote>
<p>add outputs</p>
</blockquote>
</section>
<section class="slide level2">

<p>Across runs, <strong>integer-bit = 0</strong> (i.e., all fractional) often performed best for weights/biases, matching the observed small dynamic range.</p>
</section>
<section class="slide level2">

<p><strong>Key observation:</strong> Although run-to-run variance is high, <strong>train and validation losses closely track</strong>, especially at the end. The decoder has ~<strong>2 KB</strong> of parameters vs.&nbsp;~<strong>100 MB</strong> of data, so the model capacity is too small to overfit; <em>low MSE loss</em> typically reflects genuine difficulty, not overfitting.</p>
<blockquote>
<p>add outputs</p>
</blockquote>
</section>
<section class="slide level2">

<p><strong>Implication for production:</strong> choose a reasonable configuration and <strong>rerun with new initializations</strong> until the desired metric is achieved. Under this regime, we can also quantize the encoder activation more aggressively.</p>
</section></section>
<section id="recommendations-to-the-new-qkeras-replacing-of-cern-developer-feedback" class="title-slide slide level1 center">
<h1>Recommendations to the new QKeras replacing of CERN (developer feedback)</h1>
<div class="slide" style="font-size:70%">
<ul>
<li>Add <strong>LeakyReLU-family</strong> activations support; they help both small and large models and drastically reduce dead-unit risk.</li>
<li>Prefer <strong>explicit</strong> over implicit implementation behavior and make implicit functionalities like auto quantization one top of them.</li>
<li>Move away from <strong>string-based</strong> quantizer specs; adopt Pythonic APIs (with deprecation warnings).</li>
<li>Consider <strong>drop-in PyTorch-layer equivalents</strong> for broader adoption.</li>
</ul>
</div>
</section>

<section id="references" class="title-slide slide level1 smaller scrollable">
<h1>References</h1>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-he2015delvingdeeprectifierssurpassing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">K. He, X. Zhang, S. Ren, and J. Sun, <span>“Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification.”</span> 2015. Available: <a href="https://arxiv.org/abs/1502.01852">https://arxiv.org/abs/1502.01852</a></div>
</div>
<div id="ref-DBLP:journals/corr/IoffeS15" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">S. Ioffe and C. Szegedy, <span>“Batch normalization: Accelerating deep network training by reducing internal covariate shift,”</span> <em>CoRR</em>, vol. abs/1502.03167, 2015, Available: <a href="http://arxiv.org/abs/1502.03167">http://arxiv.org/abs/1502.03167</a></div>
</div>
<div id="ref-Sheng_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">T. Sheng, C. Feng, S. Zhuo, X. Zhang, L. Shen, and M. Aleksic, <span>“A quantization-friendly separable convolution for MobileNets,”</span> in <em>2018 1st workshop on energy efficient machine learning and cognitive computing for embedded applications (EMC2)</em>, IEEE, Mar. 2018. doi: <a href="https://doi.org/10.1109/emc2.2018.00011">10.1109/emc2.2018.00011</a>.</div>
</div>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="assets/images/cern-white.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>Ali Javani - Summer Student 2025 - PicoCal Autoencoder Optimization - 03.09.2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'h.v',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/AliJavanJ1\.github\.io\/cern-presentation\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>